{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, limit the size of train/test data to 10000 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadsize=10000\n",
    "train = pd.read_csv('../Data/train.csv',nrows=loadsize,low_memory=False)\n",
    "test = pd.read_csv('../Data/test.csv',nrows=loadsize,low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>VAR_0001</th>\n",
       "      <th>VAR_0002</th>\n",
       "      <th>VAR_0003</th>\n",
       "      <th>VAR_0004</th>\n",
       "      <th>VAR_0005</th>\n",
       "      <th>VAR_0006</th>\n",
       "      <th>VAR_0007</th>\n",
       "      <th>VAR_0008</th>\n",
       "      <th>VAR_0009</th>\n",
       "      <th>...</th>\n",
       "      <th>VAR_1926</th>\n",
       "      <th>VAR_1927</th>\n",
       "      <th>VAR_1928</th>\n",
       "      <th>VAR_1929</th>\n",
       "      <th>VAR_1930</th>\n",
       "      <th>VAR_1931</th>\n",
       "      <th>VAR_1932</th>\n",
       "      <th>VAR_1933</th>\n",
       "      <th>VAR_1934</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>224</td>\n",
       "      <td>0</td>\n",
       "      <td>4300</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>998</td>\n",
       "      <td>999999998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>9998</td>\n",
       "      <td>9998</td>\n",
       "      <td>IAPS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>4448</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>998</td>\n",
       "      <td>999999998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>9998</td>\n",
       "      <td>9998</td>\n",
       "      <td>IAPS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>H</td>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>3464</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>998</td>\n",
       "      <td>999999998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>9998</td>\n",
       "      <td>9998</td>\n",
       "      <td>IAPS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>H</td>\n",
       "      <td>240</td>\n",
       "      <td>300</td>\n",
       "      <td>3200</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>998</td>\n",
       "      <td>999999998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>9998</td>\n",
       "      <td>9998</td>\n",
       "      <td>RCC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>R</td>\n",
       "      <td>72</td>\n",
       "      <td>261</td>\n",
       "      <td>2000</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>998</td>\n",
       "      <td>999999998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>9998</td>\n",
       "      <td>9998</td>\n",
       "      <td>BRANCH</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1934 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID VAR_0001  VAR_0002  VAR_0003  VAR_0004 VAR_0005  VAR_0006  VAR_0007  \\\n",
       "0   2        H       224         0      4300        C       0.0       0.0   \n",
       "1   4        H         7        53      4448        B       1.0       0.0   \n",
       "2   5        H       116         3      3464        C       0.0       0.0   \n",
       "3   7        H       240       300      3200        C       0.0       0.0   \n",
       "4   8        R        72       261      2000        N       0.0       0.0   \n",
       "\n",
       "  VAR_0008 VAR_0009   ...   VAR_1926 VAR_1927 VAR_1928   VAR_1929  VAR_1930  \\\n",
       "0    False    False   ...         98       98      998  999999998       998   \n",
       "1    False    False   ...         98       98      998  999999998       998   \n",
       "2    False    False   ...         98       98      998  999999998       998   \n",
       "3    False    False   ...         98       98      998  999999998       998   \n",
       "4    False    False   ...         98       98      998  999999998       998   \n",
       "\n",
       "   VAR_1931  VAR_1932  VAR_1933  VAR_1934  target  \n",
       "0       998      9998      9998      IAPS       0  \n",
       "1       998      9998      9998      IAPS       0  \n",
       "2       998      9998      9998      IAPS       0  \n",
       "3       998      9998      9998       RCC       0  \n",
       "4       998      9998      9998    BRANCH       1  \n",
       "\n",
       "[5 rows x 1934 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'VAR_0001', 'VAR_0002', 'VAR_0003', 'VAR_0004', 'VAR_0005',\n",
      "       'VAR_0006', 'VAR_0007', 'VAR_0008', 'VAR_0009',\n",
      "       ...\n",
      "       'VAR_1926', 'VAR_1927', 'VAR_1928', 'VAR_1929', 'VAR_1930', 'VAR_1931',\n",
      "       'VAR_1932', 'VAR_1933', 'VAR_1934', 'target'],\n",
      "      dtype='object', length=1934)\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two variables are missing from VAR_0001 to VAR_1934."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MissingVar:  ['VAR_0218', 'VAR_0240']\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "MissingVar = []\n",
    "for x in train.columns[1:-1]:\n",
    "    var = 'VAR_'+'0'*(4-len(str(i)))+str(i)\n",
    "    if x != var:\n",
    "        MissingVar.append(var)\n",
    "        i+=1\n",
    "    i+=1\n",
    "print('MissingVar: ',MissingVar)\n",
    "del MissingVar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a look at missing values. All together there are 1932 variables: VAR_0001 - VAR_1934 with VAR_0218 and VAR_0240 missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values:\n",
      "VAR_0001    0.00\n",
      "VAR_1298    0.00\n",
      "VAR_1297    0.00\n",
      "VAR_1296    0.00\n",
      "VAR_1295    0.00\n",
      "VAR_1294    0.00\n",
      "VAR_1293    0.00\n",
      "VAR_1292    0.00\n",
      "VAR_1291    0.00\n",
      "VAR_1290    0.00\n",
      "VAR_1289    0.00\n",
      "VAR_1288    0.00\n",
      "VAR_1287    0.00\n",
      "VAR_1299    0.00\n",
      "VAR_1286    0.00\n",
      "VAR_1284    0.00\n",
      "VAR_1283    0.00\n",
      "VAR_1282    0.00\n",
      "VAR_1281    0.00\n",
      "VAR_1280    0.00\n",
      "VAR_1279    0.00\n",
      "VAR_1278    0.00\n",
      "VAR_1277    0.00\n",
      "VAR_1276    0.00\n",
      "VAR_1275    0.00\n",
      "VAR_1274    0.00\n",
      "VAR_1273    0.00\n",
      "VAR_1285    0.00\n",
      "VAR_1272    0.00\n",
      "VAR_1300    0.00\n",
      "            ... \n",
      "VAR_0356    0.01\n",
      "VAR_0353    0.01\n",
      "VAR_0355    0.01\n",
      "VAR_0354    0.01\n",
      "VAR_0350    0.01\n",
      "VAR_0212    0.09\n",
      "VAR_0073    0.70\n",
      "VAR_0074    0.70\n",
      "VAR_0211    0.87\n",
      "VAR_0210    0.87\n",
      "VAR_0208    0.87\n",
      "VAR_0176    0.88\n",
      "VAR_0179    0.88\n",
      "VAR_0166    0.90\n",
      "VAR_0169    0.90\n",
      "VAR_0178    0.92\n",
      "VAR_0168    0.93\n",
      "VAR_0209    0.94\n",
      "VAR_0159    0.96\n",
      "VAR_0156    0.96\n",
      "VAR_0177    0.98\n",
      "VAR_0167    0.98\n",
      "VAR_0205    0.99\n",
      "VAR_0158    0.99\n",
      "VAR_0206    0.99\n",
      "VAR_0157    0.99\n",
      "VAR_0214    1.00\n",
      "VAR_0213    1.00\n",
      "VAR_0207    1.00\n",
      "VAR_0840    1.00\n",
      "Length: 1932, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "MissingVal = train[train.columns[1:-1]].isnull().sum().sort_values().apply(lambda x: np.round(x/train.shape[0],2))\n",
    "print('Percentage of missing values:')\n",
    "print(MissingVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete variables with missing values over 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ind = MissingVal[MissingVal>0.5].index\n",
    "train = train.drop(Ind,axis=1)\n",
    "test = test.drop(Ind,axis=1)\n",
    "del MissingVal,Ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to figure out categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = train[train.columns[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      1404\n",
       "float64     467\n",
       "object       37\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to figure out the number of categorical variables for numerical and string variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical variable value counts: \n",
      " VAR_0529       1\n",
      "VAR_0041       1\n",
      "VAR_0042       1\n",
      "VAR_0189       1\n",
      "VAR_0446       1\n",
      "VAR_0246       1\n",
      "VAR_1428       1\n",
      "VAR_0847       1\n",
      "VAR_0526       1\n",
      "VAR_0527       1\n",
      "VAR_0528       1\n",
      "VAR_0223       1\n",
      "VAR_0221       1\n",
      "VAR_0215       1\n",
      "VAR_0530       1\n",
      "VAR_0203       1\n",
      "VAR_0394       1\n",
      "VAR_0395       1\n",
      "VAR_0199       1\n",
      "VAR_0197       1\n",
      "VAR_0396       1\n",
      "VAR_0397       1\n",
      "VAR_0398       1\n",
      "VAR_0193       1\n",
      "VAR_0192       1\n",
      "VAR_0399       1\n",
      "VAR_0191       1\n",
      "VAR_0190       1\n",
      "VAR_0040       1\n",
      "VAR_0039       1\n",
      "            ... \n",
      "VAR_1801    5379\n",
      "VAR_1372    5441\n",
      "VAR_1802    5599\n",
      "VAR_0241    5677\n",
      "VAR_0652    5969\n",
      "VAR_0951    6116\n",
      "VAR_0950    6195\n",
      "VAR_0970    6242\n",
      "VAR_0649    6350\n",
      "VAR_1496    6371\n",
      "VAR_1497    6464\n",
      "VAR_0648    6661\n",
      "VAR_1494    6818\n",
      "VAR_1201    6824\n",
      "VAR_1489    6902\n",
      "VAR_0887    7236\n",
      "VAR_0704    7382\n",
      "VAR_1495    7933\n",
      "VAR_1087    8311\n",
      "VAR_0543    8410\n",
      "VAR_0541    8494\n",
      "VAR_0899    8751\n",
      "VAR_1181    8857\n",
      "VAR_1179    8904\n",
      "VAR_1180    8939\n",
      "VAR_1081    8946\n",
      "VAR_1082    8985\n",
      "VAR_0212    9119\n",
      "VAR_0227    9999\n",
      "VAR_0228    9999\n",
      "Length: 1871, dtype: int64\n",
      "String variable value counts: \n",
      " VAR_0229       1\n",
      "VAR_0216       1\n",
      "VAR_0202       1\n",
      "VAR_0196       1\n",
      "VAR_0239       1\n",
      "VAR_0222       1\n",
      "VAR_0043       1\n",
      "VAR_0044       1\n",
      "VAR_0011       1\n",
      "VAR_0010       1\n",
      "VAR_0009       1\n",
      "VAR_0008       1\n",
      "VAR_0012       1\n",
      "VAR_0236       2\n",
      "VAR_0232       2\n",
      "VAR_0466       2\n",
      "VAR_0230       2\n",
      "VAR_0226       2\n",
      "VAR_0001       3\n",
      "VAR_0467       4\n",
      "VAR_0005       4\n",
      "VAR_0354       4\n",
      "VAR_0353       4\n",
      "VAR_0352       4\n",
      "VAR_1934       5\n",
      "VAR_0283       7\n",
      "VAR_0305       7\n",
      "VAR_0325       9\n",
      "VAR_0237      42\n",
      "VAR_0342      47\n",
      "VAR_0274      56\n",
      "VAR_0493     167\n",
      "VAR_0404     230\n",
      "VAR_0217     395\n",
      "VAR_0204    1188\n",
      "VAR_0075    1447\n",
      "VAR_0200    3473\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "NumVar,NumVarIndex,ObjVar,ObjVarIndex = [],[],[],[]\n",
    "for x in Features.columns[Features.dtypes!='object']:\n",
    "    NumVar.append(len(Features[x].value_counts()))\n",
    "    NumVarIndex.append(x)\n",
    "for x in Features.columns[Features.dtypes=='object']:\n",
    "    ObjVar.append(len(Features[x].value_counts()))\n",
    "    ObjVarIndex.append(x)\n",
    "NumVar = pd.Series(NumVar,index=NumVarIndex).sort_values()\n",
    "ObjVar = pd.Series(ObjVar,index=ObjVarIndex).sort_values()\n",
    "del NumVarIndex,ObjVarIndex,Features\n",
    "print('Numerical variable value counts: \\n',NumVar)\n",
    "print('String variable value counts: \\n',ObjVar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete variables with only 1 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ind = NumVar[:len(NumVar[NumVar==1])].index\n",
    "train = train.drop(Ind,axis=1)\n",
    "test = test.drop(Ind,axis=1)\n",
    "Ind = ObjVar[:len(ObjVar[ObjVar==1])].index\n",
    "train = train.drop(Ind,axis=1)\n",
    "test = test.drop(Ind,axis=1)\n",
    "del Ind\n",
    "NumVar = NumVar[len(NumVar[NumVar==1]):]\n",
    "ObjVar = ObjVar[len(ObjVar[ObjVar==1]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the total number of the variables becomes 1845 with 1821 numerical variables and 24 string variables.\n",
      "Numerical variable value counts: \n",
      " VAR_0180       2\n",
      "VAR_0116       2\n",
      "VAR_0740       2\n",
      "VAR_0739       2\n",
      "VAR_0737       2\n",
      "VAR_0139       2\n",
      "VAR_0459       2\n",
      "VAR_0138       2\n",
      "VAR_0736       2\n",
      "VAR_0182       2\n",
      "VAR_0733       2\n",
      "VAR_0130       2\n",
      "VAR_0732       2\n",
      "VAR_0449       2\n",
      "VAR_0567       2\n",
      "VAR_0566       2\n",
      "VAR_0563       2\n",
      "VAR_0181       2\n",
      "VAR_1427       2\n",
      "VAR_0122       2\n",
      "VAR_0445       2\n",
      "VAR_0383       2\n",
      "VAR_0195       2\n",
      "VAR_0476       2\n",
      "VAR_0471       2\n",
      "VAR_0490       2\n",
      "VAR_0470       2\n",
      "VAR_0277       2\n",
      "VAR_0276       2\n",
      "VAR_0275       2\n",
      "            ... \n",
      "VAR_1801    5379\n",
      "VAR_1372    5441\n",
      "VAR_1802    5599\n",
      "VAR_0241    5677\n",
      "VAR_0652    5969\n",
      "VAR_0951    6116\n",
      "VAR_0950    6195\n",
      "VAR_0970    6242\n",
      "VAR_0649    6350\n",
      "VAR_1496    6371\n",
      "VAR_1497    6464\n",
      "VAR_0648    6661\n",
      "VAR_1494    6818\n",
      "VAR_1201    6824\n",
      "VAR_1489    6902\n",
      "VAR_0887    7236\n",
      "VAR_0704    7382\n",
      "VAR_1495    7933\n",
      "VAR_1087    8311\n",
      "VAR_0543    8410\n",
      "VAR_0541    8494\n",
      "VAR_0899    8751\n",
      "VAR_1181    8857\n",
      "VAR_1179    8904\n",
      "VAR_1180    8939\n",
      "VAR_1081    8946\n",
      "VAR_1082    8985\n",
      "VAR_0212    9119\n",
      "VAR_0227    9999\n",
      "VAR_0228    9999\n",
      "Length: 1821, dtype: int64\n",
      "String variable value counts: \n",
      " VAR_0236       2\n",
      "VAR_0232       2\n",
      "VAR_0466       2\n",
      "VAR_0230       2\n",
      "VAR_0226       2\n",
      "VAR_0001       3\n",
      "VAR_0467       4\n",
      "VAR_0005       4\n",
      "VAR_0354       4\n",
      "VAR_0353       4\n",
      "VAR_0352       4\n",
      "VAR_1934       5\n",
      "VAR_0283       7\n",
      "VAR_0305       7\n",
      "VAR_0325       9\n",
      "VAR_0237      42\n",
      "VAR_0342      47\n",
      "VAR_0274      56\n",
      "VAR_0493     167\n",
      "VAR_0404     230\n",
      "VAR_0217     395\n",
      "VAR_0204    1188\n",
      "VAR_0075    1447\n",
      "VAR_0200    3473\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Now the total number of the variables becomes %s with %s numerical variables and %s string variables.'%(len(NumVar)+len(ObjVar),len(NumVar),len(ObjVar)))\n",
    "print('Numerical variable value counts: \\n',NumVar)\n",
    "print('String variable value counts: \\n',ObjVar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values again. Fill in the missing values with the mode value for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables with missing values for train data: \n",
      " Index(['VAR_0086', 'VAR_0089', 'VAR_0088', 'VAR_0200', 'VAR_0087', 'VAR_0198',\n",
      "       'VAR_0085', 'VAR_0080', 'VAR_0082', 'VAR_0081',\n",
      "       ...\n",
      "       'VAR_0369', 'VAR_0370', 'VAR_0371', 'VAR_0372', 'VAR_0373', 'VAR_0374',\n",
      "       'VAR_0375', 'VAR_0376', 'VAR_0350', 'VAR_0212'],\n",
      "      dtype='object', length=440)\n",
      "Variables with missing values for test data: \n",
      " Index(['VAR_0086', 'VAR_0089', 'VAR_0088', 'VAR_0200', 'VAR_0087', 'VAR_0198',\n",
      "       'VAR_0085', 'VAR_0080', 'VAR_0082', 'VAR_0081',\n",
      "       ...\n",
      "       'VAR_0369', 'VAR_0370', 'VAR_0371', 'VAR_0372', 'VAR_0373', 'VAR_0374',\n",
      "       'VAR_0375', 'VAR_0376', 'VAR_0350', 'VAR_0212'],\n",
      "      dtype='object', length=440)\n"
     ]
    }
   ],
   "source": [
    "MissingValTrain = train[train.columns[1:-1]].isnull().sum().sort_values()\n",
    "MissingValTest = test[test.columns[1:]].isnull().sum().sort_values()\n",
    "MissingValTrain = MissingValTrain[MissingValTrain>0].index\n",
    "MissingValTest = MissingValTest[MissingValTest>0].index\n",
    "print('Variables with missing values for train data: \\n',MissingValTrain)\n",
    "print('Variables with missing values for test data: \\n',MissingValTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in MissingValTrain:\n",
    "    Ind = train[i][train[i].isnull()].index\n",
    "    train.loc[Ind,i]=train[i].mode()[0]\n",
    "for i in MissingValTest:\n",
    "    Ind = test[i][test[i].isnull()].index\n",
    "    test.loc[Ind,i]=test[i].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now manually process string variables.\n",
    "\n",
    "String variable value counts:\n",
    "\n",
    "VAR_0236       2\n",
    "\n",
    "VAR_0232       2\n",
    "\n",
    "VAR_0466       2\n",
    "\n",
    "VAR_0230       2\n",
    "\n",
    "VAR_0226       2\n",
    "\n",
    "VAR_0001       3\n",
    "\n",
    "VAR_0467       4\n",
    "\n",
    "VAR_0005       4\n",
    "\n",
    "VAR_0354       4\n",
    "\n",
    "VAR_0353       4\n",
    "\n",
    "VAR_0352       4\n",
    "\n",
    "VAR_1934       5\n",
    "\n",
    "VAR_0283       7\n",
    "\n",
    "VAR_0305       7\n",
    "\n",
    "VAR_0325       9\n",
    "\n",
    "VAR_0237      42\n",
    "\n",
    "VAR_0342      47\n",
    "\n",
    "VAR_0274      56\n",
    "\n",
    "VAR_0493     167\n",
    "\n",
    "VAR_0404     230\n",
    "\n",
    "VAR_0217     395\n",
    "\n",
    "VAR_0204    1188\n",
    "\n",
    "VAR_0075    1447\n",
    "\n",
    "VAR_0200    3473\n",
    "\n",
    "1. For variables with only 2 different values, directly apply LabelEncoding.\n",
    "2. For variables with >2 but <=5 different values, directly apply OneHotEncoding and drop the original variables.\n",
    "3. For VAR_0283, VAR_0305 and VAR_0325, some values only contain very few entries, categorize them as \"other\" and apply OneHotEncoding.\n",
    "4. VAR_0237, VAR_0342, VAR_0274 and VAR_0200 are state and names. By intuition we convert these string values to the frequency of each entry to represent the popularity of the service in that area.\n",
    "5. VAR_0217, VAR_0204 and VAR_0075 are datetime type variables, convert them to numerical variables.\n",
    "6. For VAR_0493 and VAR_0404, there are more than 600 values but most of the them take -1 (>90%), so categorize the rest as \"other\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For variables with only 2 different values, directly apply LabelEncoding inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ObjVar[ObjVar==2].index:\n",
    "    le=LabelEncoder()\n",
    "    le.fit(train[i])\n",
    "    train[i]=le.transform(list(train[i]))\n",
    "    test[i]=le.transform(list(test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For variables with >2 but <=5 different values, directly apply OneHotEncoding and drop the original variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in set(ObjVar[ObjVar<=5].index)-set(ObjVar[ObjVar==2].index):\n",
    "    le = LabelEncoder()\n",
    "    oh = OneHotEncoder()\n",
    "    le.fit(train[i])\n",
    "    train[i] = le.transform(list(train[i]))\n",
    "    test[i] = le.transform(list(test[i]))\n",
    "    temp = np.reshape(list(train[i]),(len(train[i]),-1))\n",
    "    oh.fit(temp)\n",
    "    temp = pd.DataFrame(oh.transform(temp).toarray(),columns=[i+'_%s'%(x) for x in range(ObjVar[i])])\n",
    "    train = pd.concat([train,temp],axis=1).drop(i,axis=1)\n",
    "    temp = np.reshape(list(test[i]),(len(test[i]),-1))\n",
    "    temp = pd.DataFrame(oh.transform(temp).toarray(),columns=[i+'_%s'%(x) for x in range(ObjVar[i])])\n",
    "    test = pd.concat([test,temp],axis=1).drop(i,axis=1)\n",
    "    del le, oh, temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. For VAR_0283, VAR_0305 and VAR_0325, some values only contain very few entries (<1% of loadsize), categorize them as \"other\" and apply OneHotEncoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-categorize data\n",
    "for i in set(ObjVar[ObjVar<10].index)-set(ObjVar[ObjVar<=5].index):\n",
    "    valcount = train[i].value_counts()\n",
    "    for j in valcount.index:\n",
    "        if valcount[j]<loadsize/100:\n",
    "            Ind = train[i][train[i]==j].index\n",
    "            train.loc[Ind,i] = 'Other'\n",
    "    valcount = test[i].value_counts()\n",
    "    for j in valcount.index:\n",
    "        if valcount[j]<loadsize/100:\n",
    "            Ind = test[i][test[i]==j].index\n",
    "            test.loc[Ind,i] = 'Other'\n",
    "    del valcount, Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply OneHotEncoding\n",
    "for i in set(ObjVar[ObjVar<10].index)-set(ObjVar[ObjVar<=5].index):\n",
    "    le = LabelEncoder()\n",
    "    oh = OneHotEncoder()\n",
    "    le.fit(train[i])\n",
    "    train[i] = le.transform(list(train[i]))\n",
    "    test[i] = le.transform(list(test[i]))\n",
    "    temp = np.reshape(list(train[i]),(len(train[i]),-1))\n",
    "    oh.fit(temp)\n",
    "    temp = pd.DataFrame(oh.transform(temp).toarray(),columns=[i+'_%s'%(x) for x in range(len(train[i].value_counts()))])\n",
    "    train = pd.concat([train,temp],axis=1).drop(i,axis=1)\n",
    "    temp = np.reshape(list(test[i]),(len(test[i]),-1))\n",
    "    temp = pd.DataFrame(oh.transform(temp).toarray(),columns=[i+'_%s'%(x) for x in range(len(test[i].value_counts()))])\n",
    "    test = pd.concat([test,temp],axis=1).drop(i,axis=1)\n",
    "    del le, oh, temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. VAR_0237, VAR_0342, VAR_0274 and VAR_0200 are state and names. By intuition we convert these string values to the frequency of each entry to represent the popularity of the service in that area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = ['VAR_0237', 'VAR_0342', 'VAR_0274', 'VAR_0200']\n",
    "for i in Features:\n",
    "    valcount = train[i].value_counts()\n",
    "    for j in valcount.index:\n",
    "        Ind = train[i][train[i] == j].index\n",
    "        train.loc[Ind,i] = valcount[j]\n",
    "    valcount = test[i].value_counts()\n",
    "    for j in valcount.index:\n",
    "        Ind = test[i][test[i] == j].index\n",
    "        test.loc[Ind,i] = valcount[j]\n",
    "    del valcount, Ind\n",
    "del Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. VAR_0217, VAR_0204 and VAR_0075 are datetime type variables, convert them to numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = ['VAR_0217', 'VAR_0204', 'VAR_0075']\n",
    "Month = {'JAN':'01','FEB':'02','MAR':'03','APR':'04','MAY':'05','JUN':'06','JUL':'07','AUG':'08','SEP':'09','OCT':'10','NOV':'11','DEC':'12'}\n",
    "\n",
    "for i in Features:\n",
    "    train[i] = train[i].apply(lambda x: int('20'+x[5:7]+Month[x[2:5]]+x[:2]+x[8:10]+x[11:13]+x[14:]))\n",
    "    test[i] = test[i].apply(lambda x: int('20'+x[5:7]+Month[x[2:5]]+x[:2]+x[8:10]+x[11:13]+x[14:]))\n",
    "\n",
    "del Features, Month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. For VAR_0493 and VAR_0404, there are more than 600 values but most of the them take -1 (>90%), so categorize the rest as \"other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = ['VAR_0493', 'VAR_0404']\n",
    "\n",
    "for i in Features:\n",
    "    Ind = train[i][train[i]!='-1'].index\n",
    "    train.loc[Ind,i] = 0\n",
    "    Ind = train[i][train[i]=='-1'].index\n",
    "    train.loc[Ind,i] = -1\n",
    "    Ind = test[i][test[i]!='-1'].index\n",
    "    test.loc[Ind,i] = 0\n",
    "    Ind = test[i][test[i]=='-1'].index\n",
    "    test.loc[Ind,i] = -1\n",
    "del Ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all the missing values have been filled and all the variables have been converted to numerical variables, we are ready to train our model. \n",
    "\n",
    "Use GridSearchCV to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print('Begin training the model...')\n",
    "ID = test.ID\n",
    "\n",
    "parameters = {\n",
    "        'max_depth': [3,4],\n",
    "        'learning_rate': [0.05,0.10,0.15],\n",
    "        'n_estimators': [50,100]\n",
    "    }\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    max_depth=3, \n",
    "    learning_rate=0.05,\n",
    "    objective='binary:logistic', \n",
    "    eval_metric='auc',\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "gsearch = GridSearchCV(model, param_grid=parameters, scoring='roc_auc', cv=3)\n",
    "gsearch.fit(train.drop(['ID','target'],axis=1),train.target)\n",
    "print(\"Best score: %0.3f\" % gsearch.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = gsearch.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74667317, 0.76031469, 0.74700903, 0.75872523, 0.75594737])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(\n",
    "    max_depth=3, \n",
    "    learning_rate=0.10,\n",
    "    objective='binary:logistic', \n",
    "    eval_metric='auc',\n",
    "    n_estimators=100\n",
    ")\n",
    "cross_val_score(model,train.drop(['ID','target'],axis=1),train.target,scoring='roc_auc',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(\n",
    "        max_depth=3, \n",
    "        learning_rate=0.10,\n",
    "        objective='binary:logistic', \n",
    "        eval_metric='auc',\n",
    "        n_estimators=100\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train.drop(['ID','target'],axis=1), train.target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
